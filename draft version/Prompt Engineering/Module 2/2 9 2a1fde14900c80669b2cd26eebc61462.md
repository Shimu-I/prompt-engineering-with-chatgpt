# 2.9

## üß© **Module 2.9 ‚Äî Exam Section: Quiz + Role-Based Prompt Task**

*(Section 1.2.2.9 of the syllabus)*

---

### **Part A: Concept Foundations**

### **Purpose of This Exam Section**

This final segment of **Module 2: Understanding Prompts and Responses** evaluates how well you can:

1. Identify and structure prompt components (instruction, context, format).
2. Control tone, style, and temperature for consistent results.
3. Troubleshoot, rewrite, and validate your prompts effectively.
4. Demonstrate role-based prompting ‚Äî the cornerstone of professional-grade AI collaboration.

> üí¨ Think of this exam not as a test of memory, but as a simulation of how a real prompt engineer solves ambiguity, precision, and performance challenges.
> 

---

### **Part B: Knowledge & Application Quiz**

### **üßæ Section 1: Objective Questions (MCQ & Short Answer)**

| **Q#** | **Question** | **Type** |
| --- | --- | --- |
| 1 | What are the three layers of a prompt‚Äôs structure? | Short Answer |
| 2 | How does temperature affect the creativity of an AI‚Äôs response? | Short Answer |
| 3 | Which of the following is a *prompt anti-pattern*? a) Defining role and tone b) Mixing multiple unrelated tasks c) Using schema validation | MCQ |
| 4 | What‚Äôs the main difference between ‚Äútone‚Äù and ‚Äústyle‚Äù? | Short Answer |
| 5 | Why do we use output schemas (like JSON) in prompt engineering? | Short Answer |
| 6 | What‚Äôs the first step of the 3C troubleshooting model? | Short Answer |
| 7 | In prompt rewriting, what does the R.E.S.E.T. framework‚Äôs ‚ÄúS‚Äù stand for? | Short Answer |
| 8 | What instruction would you add to prevent schema drift in a JSON output? | Short Answer |
| 9 | Define a hidden task with an example. | Short Answer |
| 10 | Which part of the prompt defines how the response *looks*, not what it *means*? | MCQ |

---

### ‚úÖ **Answer Key**

| **Q#** | **Correct Answer** | **Explanation** |
| --- | --- | --- |
| 1 | Instruction, Context, Output Format | These define purpose, scope, and structure. |
| 2 | Higher temperature increases creativity but decreases predictability. | It diversifies word choices and phrasing. |
| 3 | (b) Mixing multiple unrelated tasks | Causes confusion and incomplete responses. |
| 4 | Tone = emotional attitude; Style = presentation method. | Example: persuasive tone vs analytical style. |
| 5 | For structured, machine-readable, and validated responses. | Enables automation and consistency. |
| 6 | Clarity | Ensure the task is explicitly defined. |
| 7 | Specify Output | Controls format, tone, and structure. |
| 8 | ‚ÄúOutput only valid JSON, with no extra commentary.‚Äù | Enforces format guardrails. |
| 9 | Combining multiple cognitive tasks in one instruction (e.g., ‚ÄúSummarize and rewrite as a poem‚Äù). | Causes confusion or partial completion. |
| 10 | Output Format | Determines structure and readability. |

---

### **Part C: Role-Based Prompt Design Task**

### **Task Overview**

You will now design **two role-based prompts** for the *same goal*, each optimized for a different professional persona.

This exercise tests your ability to **translate intent into context-specific instructions**.

---

### **Goal:**

> Generate a summary of how artificial intelligence is transforming education.
> 

---

### **Prompt 1 ‚Äî Role: Research Analyst**

```
Act as an educational technology researcher.
Write a 200-word analytical summary of how AI is transforming education.
Focus on data-driven instruction, adaptive learning systems, and student analytics.
Use a formal and objective tone.
Output in three paragraphs: Introduction, Key Insights, Conclusion.

```

‚úÖ *Evaluation: Structured, academic tone, clear segmentation.*

---

### **Prompt 2 ‚Äî Role: Journalist**

```
Act as a tech journalist.
Write a 200-word article on how AI is transforming education.
Focus on storytelling and human impact ‚Äî include 1 student success story.
Use a conversational tone and an engaging opening line.
Output as short paragraphs with a catchy headline.

```

‚úÖ *Evaluation: Story-driven, audience-aware, emotional engagement.*

---

### **Reflection Question**

> How did changing the role alter your phrasing, tone, and structure?
> 
> 
> Which version would better fit a blog post vs a research report ‚Äî and why?
> 

---

### **Part D: Advanced Challenge ‚Äî Prompt Debug Simulation**

### **Scenario:**

You‚Äôre working as a prompt engineer for a company building an AI tutor.

You write this initial prompt:

```
Explain algebra for students.

```

The client says the response was too vague and generic.

**Your Task:**

1. Diagnose the issues (use 3C framework).
2. Rewrite the prompt using R.E.S.E.T. principles.
3. Add one schema or formatting guardrail.

---

### **Expected Example Solution**

**Diagnosis (3C):**

- **Clarity:** ‚ÄúExplain algebra‚Äù is too broad.
- **Context:** Missing student level.
- **Constraints:** No tone or output limit.

**Rewritten Prompt:**

```
Act as a math tutor for 9th-grade students.
Explain the basics of algebra using simple language and real-world analogies.
Limit to 150 words and include 2 example equations.
Output as bullet points with clear labels.

```

**Schema Guardrail:**

‚ÄúDo not include unrelated topics or definitions outside algebra basics.‚Äù

‚úÖ *Result: Focused, contextual, verifiable.*

---

### **Part E: Self-Assessment and Scoring**

### **Self-Reflection Prompts**

> Which part of prompt design do you find most natural ‚Äî structure, tone, or troubleshooting?Which area requires more practice?How will you apply schema and role-based design in your own projects?
> 

---

### **Instructor Scoring Rubric**

| **Criterion** | **Max Points** | **Evaluation Criteria** |
| --- | --- | --- |
| Knowledge Quiz | 20 | Accuracy and conceptual understanding |
| Role-Based Task | 30 | Creativity, clarity, and consistency |
| Debug Simulation | 30 | Application of frameworks and fixes |
| Reflection | 20 | Depth of insight and articulation |

**Total Score: 100**

| **Score Range** | **Performance Level** | **Description** |
| --- | --- | --- |
| 90‚Äì100 | ‚≠ê **Expert Prompt Architect** | Mastery of structure, tone, and control |
| 75‚Äì89 | ‚úÖ **Proficient Practitioner** | Solid practical command; minor refinement needed |
| 60‚Äì74 | ‚öôÔ∏è **Developing Engineer** | Good fundamentals, needs more troubleshooting depth |
| <60 | üß© **Beginner Tier** | Revisit Modules 2.1‚Äì2.5 for foundational improvement |

---

‚úÖ **Summary Insight:**

> This exam brings everything together ‚Äî structure, tone, context, constraints, and schema validation.
> 
> 
> The real mastery isn‚Äôt just *knowing* what a prompt is ‚Äî it‚Äôs being able to **diagnose, refine, and repurpose it dynamically across roles and goals.**
>