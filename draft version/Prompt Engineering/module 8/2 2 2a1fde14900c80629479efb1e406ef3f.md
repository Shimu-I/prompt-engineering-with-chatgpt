# 2.2

## **1.4.2.2 Working with Files and Data**

---

### **Part A – Concept Foundations**

---

### **1️⃣ Why File Handling Matters in ADA**

The true strength of ADA lies in its ability to **interact with files directly** — reading, writing, transforming, and visualizing data in real time.

It elevates ChatGPT from a text-based generator into a **data-capable AI collaborator**.

> 🧠 Analogy:
> 
> 
> Think of ADA like an “AI Data Studio.”
> 
> You bring in raw materials (files), ADA opens them, cleans them, transforms them, and hands you structured insight — all within chat.
> 

---

### **2️⃣ Supported File Types and Actions**

| **File Type** | **Typical Purpose** | **Supported Actions in ADA** |
| --- | --- | --- |
| `.csv`, `.xlsx` | Tabular data | Read, filter, merge, summarize tables |
| `.json`, `.txt` | Config or log data | Parse, transform to tables |
| `.pdf`, `.docx` | Reports and text | Extract text for analysis |
| `.zip` | Archives of data files | Unpack and process internals |
| `.png`, `.jpg` | Images or charts | Load metadata or embed in report |

✅ You can upload multiple files simultaneously, reference them by name, and ADA tracks them in the session context.

---

### **3️⃣ Typical File Workflows**

| **Task** | **Prompt Example** |
| --- | --- |
| Load and inspect dataset | “Upload `sales_data.csv` and show the first 10 rows.” |
| Combine data sources | “Merge `january.xlsx` and `february.xlsx` on ‘customer_id’.” |
| Clean and normalize data | “Fill missing values and convert dates to YYYY-MM-DD.” |
| Export processed output | “Save the cleaned file as `summary.csv`.” |
| Extract text from documents | “Read `report.pdf` and list all section headings.” |

---

### **4️⃣ Best Practices for Data Handling**

| **Practice** | **Why It Matters** | **Example** |
| --- | --- | --- |
| **Always inspect the first rows** | Validate format and encoding | `df.head()` before analysis |
| **Check data types** | Prevent type errors | Ensure numeric columns are floats |
| **Avoid overwriting original files** | Maintain data integrity | Export as new version (`v2`) |
| **Clean missing values early** | Downstream models need consistency | Use `.fillna()` or interpolation |
| **Keep output structured** | Enables reuse and reporting | Return JSON/CSV instead of raw text |

---

### **Part B – Application and Examples**

---

### **Example 1 – Combining and Cleaning Files**

```
Prompt:
"Upload january_sales.csv and february_sales.csv.
Merge them, remove duplicates, and calculate total revenue by region."

```

✅ ADA executes pandas merge → drop_duplicates → groupby, returning a summary table.

---

### **Example 2 – JSON Transformation**

```
Prompt:
"Read config.json and convert it to a two-column table of key and value."

```

✅ Transforms nested JSON into tabular format for easy inspection.

---

### **Example 3 – PDF Content Extraction**

```
Prompt:
"Extract all section headings from report.pdf and count the occurrences of 'AI'."

```

✅ ADA uses text parsing to summarize documents automatically.

---

### **Example 4 – Exporting Cleaned Data**

```
Prompt:
"Remove all rows with missing revenue and export cleaned data as clean_sales.csv."

```

✅ The file is created in the session and available for download.

---

### **Example 5 – Chaining File Tasks**

```
Prompt:
"Upload raw_data.zip, extract contents, combine all CSVs, calculate averages, and export results to combined_report.csv."

```

✅ Illustrates multi-stage file automation within one workflow.

---

### **Part C – Reflection, Quiz & Mini Project**

---

### **Reflection Prompt**

> Think about how you currently handle data outside ChatGPT.
> 
> 
> How many tools does it take to load, clean, visualize, and export data?
> 
> How could ADA reduce this toolchain into one intelligent prompt session?
> 

---

### **Quick Quiz**

| **Q#** | **Question** | **Type** |
| --- | --- | --- |
| 1 | Name three file types ADA can process. | Short Answer |
| 2 | What command shows the first few rows of a dataset? | Short Answer |
| 3 | Why is it important to check data types before analysis? | Short Answer |
| 4 | How can you merge two Excel files in ADA? | Short Answer |
| 5 | What’s a safe practice when exporting processed data? | Short Answer |

---

### **Answer Key**

| **Q#** | **Answer** | **Explanation (Rebux)** |
| --- | --- | --- |
| 1 | CSV, XLSX, JSON, PDF, TXT | Common data and document formats. |
| 2 | `df.head()` or “show first rows.” | Checks structure and encoding. |
| 3 | Incorrect types cause math or merge errors. | Ensures data integrity. |
| 4 | Upload both files → prompt “merge on key_column.” | ADA executes pandas merge. |
| 5 | Export under a new name (e.g., `cleaned_v2.csv`). | Preserves original data. |

---

### **Mini Project – “Multi-File Integration Workflow”**

> Goal: Combine, analyze, and export datasets from different sources using ADA.
> 

| **Step** | **Instruction** | **Example** |
| --- | --- | --- |
| 1️⃣ | Upload two or more data files. | `upload sales_q1.csv` and `sales_q2.csv`. |
| 2️⃣ | Inspect data and identify common columns. | “Show columns from both datasets.” |
| 3️⃣ | Merge and clean. | “Merge on customer_id, drop null rows.” |
| 4️⃣ | Summarize results. | “Compute average sales by region.” |
| 5️⃣ | Export final dataset. | “Save as cleaned_sales_2025.csv.” |

✅ *Advanced Option:* Add reflection — “Compare this run’s totals with previous file versions and report differences.”

---

### **Instructor Rubric (Optional)**

| **Criterion** | **Score (1–10)** | **Focus Area** |
| --- | --- | --- |
| File Handling Accuracy |  | Correct reading and merging of files |
| Data Cleaning Quality |  | Completeness and consistency |
| Output Structure |  | Well-formatted and labeled data |
| Workflow Clarity |  | Logical sequence of operations |
| Reflection Depth |  | Insight on data decisions |

---

✅ **Summary Insight**

> ADA makes prompt engineers data-capable analysts.
> 
> 
> You no longer need separate IDE or scripts to clean or merge data — everything is done through reasoned prompt interactions.
> 
> 💡 *Prompt Engineering Principle:*
> 
> “Files are data. Prompts are pipelines. Together, they create insight.”
>