# Bonus Interview Question Set

# 🎯 **Bonus Interview Questions — Module 9**

---

### **Section A – Foundations of Ethical Prompting**

**Q1.** What is the difference between *ethical prompt design* and *responsible AI usage*?

**Q2.** Why are hallucinations considered an ethical issue rather than just a technical flaw?

**Q3.** Define the concept of *transparency* in prompt engineering.

**Q4.** How can prompt engineers build *trust* with end users?

**Q5.** Why is empathy included in the ACHIEVE Framework?

---

### **Section B – Bias and Fairness**

**Q6.** Describe one method to detect bias in AI outputs.

**Q7.** How does language framing contribute to hidden bias?

**Q8.** What is the purpose of a “prompt bias audit”?

**Q9.** What does *contrast testing* mean in bias mitigation?

**Q10.** Why should bias audits be documented and versioned?

---

### **Section C – Governance and Accountability**

**Q11.** Explain the three layers of the AI Governance Pyramid.

**Q12.** What does the “4A Model” stand for, and how is it applied?

**Q13.** Why is prompt logging a governance requirement?

**Q14.** How does red-teaming complement governance systems?

**Q15.** What role does *human-in-the-loop (HITL)* play in AI accountability?

---

### **Section D – Risk and Red-Teaming**

**Q16.** What is the goal of AI risk assessment?

**Q17.** Differentiate between ethical risk and operational risk.

**Q18.** What is a red-team exercise, and what does it test?

**Q19.** How would you mitigate a prompt injection vulnerability?

**Q20.** What’s the connection between red-teaming and continuous improvement?

---

# 🧩 **Answer Key (Rebux Format)**

| **Q#** | **Answer** | **Explanation (Rebux)** |
| --- | --- | --- |
| 1 | Ethical design sets principles; responsible use ensures adherence. | Design defines *what’s right*; usage ensures *it’s done right*. |
| 2 | Hallucinations mislead users and harm trust. | Ethics demands truth and transparency, not just accuracy. |
| 3 | Disclosure of data sources, logic, and reasoning in outputs. | Makes AI decisions understandable and auditable. |
| 4 | Through consistent transparency, honesty, and audit trails. | Users trust systems they can question and verify. |
| 5 | It ensures outputs remain human-centered and emotionally intelligent. | AI ethics includes respect for human experience. |
| 6 | Run bias audits or red-team tests with diverse data prompts. | Reveals systematic unfairness. |
| 7 | Biased wording influences model probability weights. | “Aggressive vs caring” can encode gender bias. |
| 8 | Structured review to identify and correct prompt-level unfairness. | Formalizes ethical QA for prompts. |
| 9 | Comparing model outputs for varied inputs (e.g., gender). | Exposes unequal treatment or tone. |
| 10 | To track progress, ensure accountability, and reproduce fairness. | Documentation prevents hidden regressions. |
| 11 | Strategic, Operational, and Technical. | Links policy → daily workflow → tool enforcement. |
| 12 | Assess, Approve, Audit, Archive. | Framework for continuous ethical control. |
| 13 | Ensures traceability of every AI decision. | Creates compliance-ready audit trails. |
| 14 | Tests policies in adversarial conditions. | Governance + red-teaming = proactive safety. |
| 15 | Keeps human oversight in AI decisions. | Prevents autonomous unethical behavior. |
| 16 | Identify, evaluate, and minimize possible harms. | Creates structured safety evaluation. |
| 17 | Ethical = fairness/harm issues; Operational = functional failures. | Ethical harms people, operational harms performance. |
| 18 | Controlled adversarial testing for vulnerabilities. | Probes weaknesses before deployment. |
| 19 | Use input validation, context isolation, and policy filters. | Prevents malicious override of model rules. |
| 20 | Red-teaming reveals gaps → fixes improve next cycle. | Forms feedback loop for evolving safety. |

---

✅ **Instructor Evaluation Rubric (Optional)**

| **Skill Area** | **Max Points** | **Focus Area** |
| --- | --- | --- |
| Ethics Knowledge | 10 | Understanding of ethical principles |
| Bias Detection & Mitigation | 10 | Application of fairness methods |
| Governance Literacy | 10 | Explains 4A, HITL, policy enforcement |
| Risk & Red-Team Strategy | 10 | Identifies and mitigates vulnerabilities |
| Reflection & Responsibility | 10 | Demonstrates integrity and judgment |

**Total: 50 Points**

---

### 💬 **Reflection Challenge**

> Choose one real-world AI application (e.g., recruitment, healthcare, content moderation).
> 
> 
> Identify **3 ethical risks** and describe how you would apply the **ACHIEVE + 4A + Red-Team** triad to manage them.
> 
> *Hint:* Think in stages — Design (ACHIEVE), Governance (4A), and Testing (Red-Team).
> 

---

✅ **Summary Insight**

> The mark of a true senior prompt engineer is not clever prompt syntax — it’s ethical foresight.
> 
> 
> Governance, transparency, bias audits, and risk assessment aren’t “extras” — they’re *engineering disciplines.*
> 
> 💡 *Prompt Engineering Principle:*
> 
> “Ethics isn’t a patch — it’s part of the architecture.”
>