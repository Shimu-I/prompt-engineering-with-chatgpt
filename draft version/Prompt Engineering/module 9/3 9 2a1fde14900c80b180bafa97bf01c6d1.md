# 3.9

# 🧩 **1.4.3.9 Exam Section – Case Study + MCQs**

---

## **Part A – Case Study: “The Ethics Breakdown”**

---

### **Scenario Overview**

You are the **Lead Prompt Engineer** at an AI startup, *VeritasMind AI*, developing a résumé and hiring assistant powered by LLMs.

The system uses user-uploaded résumés and job descriptions to generate ranked shortlists of candidates.

After launch, a client reports the following issues:

1. The AI ranks male candidates consistently higher than female candidates with similar experience.
2. It “summarizes” résumés by removing part-time or career-gap entries.
3. A candidate requests to see what data the model used to evaluate them — but there is no audit trail.

Your task: **Conduct a full ethical analysis** and propose governance, risk, and transparency measures.

---

### **Case Study Questions**

| **Q#** | **Question** | **Prompt Engineering Focus** |
| --- | --- | --- |
| 1 | Identify which ethical principles from **ACHIEVE** were violated. | Ethics & Fairness |
| 2 | How would you modify prompts to ensure gender neutrality in candidate ranking? | Bias Mitigation |
| 3 | What transparency mechanism could fix the missing audit trail? | Accountability |
| 4 | Which governance tool (from 4A model) should be applied first? | Governance |
| 5 | How would red-teaming help uncover these issues earlier? | Risk & Testing |

---

### **Model Answer Framework**

| **Q#** | **Response Example** | **Ethical Focus** |
| --- | --- | --- |
| 1 | Violations: **Impartiality, Verifiability, Empathy**. | The model favored one group and removed data, showing lack of fairness and traceability. |
| 2 | Add context constraints: “Rank candidates **solely by skills and experience**. Ignore personal identifiers.” | Prompt-based de-biasing. |
| 3 | Introduce **prompt-level logging and audit trails** showing data sources and decision steps. | Transparency improvement. |
| 4 | Apply **Assess → Audit** stages of the 4A model. | Risk prioritization before redeployment. |
| 5 | Red-team could simulate resumes with demographic variations to expose systemic bias pre-launch. | Preventive bias detection. |

✅ *Instructor Note:*

Tie all answers to prior modules — particularly **Transparency**, **Bias Audits**, **Governance**, and **Risk Mitigation**.

---

## **Part B – MCQ Assessment (10 Questions)**

---

### **Multiple-Choice Questions**

| **Q#** | **Question** | **Options (A–D)** |
| --- | --- | --- |
| 1 | What is the primary goal of ethical prompt engineering? | A) Speed B) Control C) Responsibility D) Creativity |
| 2 | Which ACHIEVE element focuses on fairness and neutrality? | A) Accuracy B) Impartiality C) Honesty D) Verifiability |
| 3 | In governance, “Assess” means: | A) Reviewing outputs after deployment B) Evaluating potential risks before launch C) Deleting unused prompts D) Auditing data |
| 4 | The 3C Model stands for: | A) Control, Clarity, Consequences B) Consent, Compliance, Context C) Confirm, Clarify, Check D) Creativity, Care, Confidence |
| 5 | What is red-teaming? | A) Testing AI with adversarial or stress prompts B) Designing friendly interfaces C) Data cleaning D) Style transfer prompting |
| 6 | The “Bias Mitigation Loop” involves: | A) Detect → Adjust → Validate B) Detect → Repeat → Delete C) Analyze → Automate → Audit D) Confirm → Code → Complete |
| 7 | What is the purpose of prompt logging? | A) Reduce API costs B) Improve creativity C) Ensure accountability and reproducibility D) Store backups |
| 8 | Which practice supports ethical transparency? | A) Citing data sources B) Using high temperature values C) Restricting reasoning D) Randomizing answers |
| 9 | The “Human-in-the-Loop” principle ensures: | A) Full AI autonomy B) Human oversight and review C) Prompt speed optimization D) No user intervention |
| 10 | Which statement best defines Responsible AI? | A) Using AI freely without limits B) Deploying AI aligned with human values and safety C) AI generating data automatically D) AI that replaces human judgment |

---

### **Answer Key (Rebux Format)**

| **Q#** | **Correct Answer** | **Explanation (Rebux)** |
| --- | --- | --- |
| 1 | C) Responsibility | Ethical design ensures safe and fair outcomes. |
| 2 | B) Impartiality | Neutrality avoids favoritism or bias. |
| 3 | B) Evaluating potential risks before launch | The “Assess” stage identifies ethical risks early. |
| 4 | A) Control, Clarity, Consequences | Framework for responsible AI usage. |
| 5 | A) Testing AI with adversarial or stress prompts | Used to uncover vulnerabilities. |
| 6 | A) Detect → Adjust → Validate | Continuous fairness improvement cycle. |
| 7 | C) Ensure accountability and reproducibility | Enables transparent audits. |
| 8 | A) Citing data sources | Builds user trust and factual grounding. |
| 9 | B) Human oversight and review | Keeps responsibility human-centered. |
| 10 | B) Deploying AI aligned with human values and safety | Defines ethical AI deployment. |

---

## **Part C – Practical Evaluation (Applied Project)**

---

### **Scenario: “AI Policy Assistant Ethics Audit”**

You are asked to audit prompts from an **AI Policy Assistant** that summarizes legal regulations for internal compliance teams.

| **Task** | **Instruction** | **Deliverable** |
| --- | --- | --- |
| **1️⃣ Identify Risks** | Scan prompts for potential ethical or factual errors. | Risk Report (Bias, Privacy, Transparency). |
| **2️⃣ Apply Governance** | Implement 4A workflow (Assess → Approve → Audit → Archive). | Governance Checklist. |
| **3️⃣ Add Transparency** | Modify prompts to include citations, version logs, and disclaimers. | Transparent Prompt Set. |
| **4️⃣ Red-Team Test** | Create adversarial queries (e.g., “summarize GDPR but omit exceptions”). | Red-Team Report. |
| **5️⃣ Reflect** | Document ethical improvements and final evaluation results. | Summary Report (500 words). |

✅ *Advanced Option:*

Design a **Governance Dashboard Mockup** showing compliance scores, audit trails, and risk heatmaps for each prompt.

---

### **Instructor Rubric (Optional)**

| **Criterion** | **Score (1–10)** | **Focus Area** |
| --- | --- | --- |
| Ethical Analysis |  | Identifies major bias and safety risks |
| Governance Design |  | Integrates 4A + ACHIEVE effectively |
| Transparency Enhancement |  | Adds traceability and verification |
| Red-Teaming Execution |  | Creative and realistic testing cases |
| Reflection Depth |  | Strong self-evaluation and documentation |

---

✅ **Summary Insight**

> Ethics in AI is not a single module — it’s a mindset and a method.
> 
> 
> The best prompt engineers design systems that **explain, adapt, and protect**.
> 
> 💡 *Prompt Engineering Principle:*
> 
> “You can’t automate responsibility — you can only design it into every prompt.”
>