# 1.9

## üß© **Module 1.9 ‚Äì Exam Section: MCQ + Short Answers + Mini Project**

*(Evaluating mastery of ‚ÄúIntroduction to Generative AI and ChatGPT‚Äù)*

---

### **Part A ‚Äì Purpose and Overview**

This final assessment evaluates your command of:

1. **Foundational Concepts** ‚Äì Generative AI, LLMs, and transformer logic
2. **Prompt Design Skills** ‚Äì Role, context, structure, and iteration
3. **Analytical Reasoning** ‚Äì Understanding limits and capabilities
4. **Practical Application** ‚Äì Hands-on prompt creation and reflection

> üß† Analogy:
> 
> 
> Think of this exam like your first AI ‚Äúflight check.‚Äù
> 
> You‚Äôve learned the theory ‚Üí now you‚Äôll prove you can *take off, navigate, and land* an interaction safely and intelligently.
> 

---

### **Part B ‚Äì Section 1: Multiple Choice Questions (MCQ)**

| **Q#** | **Question** | **Options** | **Correct Answer / Explanation** |
| --- | --- | --- | --- |
| 1 | What is the primary goal of generative AI? | a) Label data  b) Generate new content  c) Detect spam  d) Store information | ‚úÖ b) Generates new text, images, code from learned patterns. |
| 2 | Which architecture revolutionized modern LLMs? | a) CNN  b) RNN  c) Transformer  d) GAN | ‚úÖ c) Transformer ‚Äì introduced self-attention. |
| 3 | In prompt engineering, which phrase best defines a ‚Äúrole‚Äù? | a) Output format  b) Persona for the model  c) User intent  d) Temperature setting | ‚úÖ b) Persona directs tone and context. |
| 4 | Which parameter controls creativity and randomness in responses? | a) Max tokens  b) Temperature  c) Top-p  d) Frequency penalty | ‚úÖ b) Temperature ‚Äì higher = more creative. |
| 5 | Which is *not* a strength of LLMs? | a) Text generation  b) Pattern recognition  c) Real-time data retrieval  d) Summarization | ‚úÖ c) They lack live knowledge without tools. |
| 6 | A prompt that contains multiple conflicting instructions is an example of what? | a) Chain prompt  b) Anti-pattern  c) CoT  d) Fine-tuning | ‚úÖ b) Prompt anti-pattern ‚Äì causes ambiguity. |
| 7 | Which tool extends ChatGPT‚Äôs data-analysis abilities? | a) DALL¬∑E  b) Browser  c) ADA  d) Memory | ‚úÖ c) Advanced Data Analysis (Code Interpreter). |
| 8 | Context window refers to ___. | a) Output speed  b) Token limit memory  c) Temperature setting  d) Model version | ‚úÖ b) The maximum tokens the model processes at once. |
| 9 | Which OpenAI model is multimodal (text + image + audio)? | a) GPT-4  b) GPT-4o  c) GPT-3.5  d) DALL¬∑E | ‚úÖ b) GPT-4o (Omni). |
| 10 | Which loop best describes human-AI collaboration? | a) Feedback loop  b) AI interaction loop  c) Context loop  d) Data loop | ‚úÖ b) Prompt ‚Üí Inference ‚Üí Evaluation ‚Üí Refinement. |

---

### **Part C ‚Äì Section 2: Short Answer Questions**

| **Q#** | **Question** | **Model Answer Summary** |
| --- | --- | --- |
| 11 | Define prompt engineering in one sentence. | The structured design of AI inputs to produce controlled, purposeful outputs. |
| 12 | List the three essential parts of a prompt. | Role / Task / Format. |
| 13 | What does the ‚Äúattention‚Äù mechanism allow LLMs to do? | Identify which tokens influence each other most, enabling contextual reasoning. |
| 14 | Explain why LLMs sometimes hallucinate. | They predict plausible text without verifying truth; no direct database or awareness. |
| 15 | What‚Äôs the benefit of using a persona in prompts? | Ensures consistent tone and domain-specific style in output. |
| 16 | Name two open-source LLM families. | LLaMA and Mistral (or Falcon, Gemma etc.). |
| 17 | What is the AI Interaction Loop used for? | Iteratively refining AI responses through feedback and prompt adjustment. |
| 18 | How can you reduce creativity drift in technical answers? | Lower temperature and add ‚Äúbe precise and factual‚Äù instruction. |
| 19 | Describe a real-world use case for ChatGPT tools. | ADA for data analysis reports from CSV files; DALL¬∑E for visual design. |
| 20 | Why is understanding limits important for trustworthy AI use? | Prevents over-reliance, enables safe and ethical prompt design. |

---

### **Part D ‚Äì Section 3: Mini Project ‚Äì Applied Prompt Task**

### **Task Title:** *‚ÄúDesign and Evaluate Your First Structured Prompt‚Äù*

> Objective: Demonstrate the ability to apply the Prompt Anatomy (Role + Task + Format) and AI Interaction Loop to produce and refine a high-quality response.
> 

---

### **Instructions**

1. **Choose a Real-World Scenario:**
    
    (e.g., education, marketing, coding, research, storytelling).
    
2. **Write an initial prompt** that requests an AI output for that scenario.
3. **Run it in ChatGPT or API.** Observe the response.
4. **Evaluate it** for clarity, accuracy, tone, and usefulness.
5. **Refine your prompt** using the 3C Framework (Clarity / Context / Constraints).
6. **Compare before-and-after outputs.** Describe the improvement.

---

### **Deliverable Template**

| **Item** | **Your Work** |
| --- | --- |
| Scenario Title |  |
| Initial Prompt |  |
| Initial Output Summary |  |
| Identified Issues |  |
| Refined Prompt |  |
| Improved Output Summary |  |
| Key Learning / Reflection (150‚Äì200 words) |  |

> üß© Optional Extension:
> 
> 
> Attach screenshots or code snippets if you use the API version.
> 

---

### **Part E ‚Äì Self-Reflection and Evaluation**

### **Reflection Prompts**

- How did iteration improve your output quality?
- Which stage of the AI Interaction Loop felt most natural to you?
- What specific prompting technique (role, tone, format) made the biggest difference?
- How will you apply these skills in future modules or projects?

---

### **Part F ‚Äì Instructor Scoring Rubric**

| **Criterion** | **Max Points** | **Evaluation Criteria** |
| --- | --- | --- |
| Knowledge Quiz (MCQ + Short) | 40 pts | Accuracy and concept recall across modules 1.1‚Äì1.8. |
| Prompt Design (Structure + Creativity) | 25 pts | Clear role/task/format; innovative and purpose-fit design. |
| Iteration and Analysis | 20 pts | Shows effective use of AI Interaction Loop and evaluation. |
| Reflection and Ethical Awareness | 15 pts | Insight into limits, bias, and responsible use. |

**Total = 100 points**

---

### **Performance Interpretation**

| **Score Range** | **Level** | **Descriptor** |
| --- | --- | --- |
| 90 ‚Äì 100 | ‚≠ê Expert Prompt Architect | Demonstrates deep understanding and real-world application. |
| 75 ‚Äì 89 | ‚úÖ Proficient Practitioner | Solid conceptual grasp and effective prompt refinement. |
| 60 ‚Äì 74 | ‚öôÔ∏è Developing Engineer | Basic competence with some iteration gaps. |
| < 60 | üß© Beginner Tier | Needs to review core concepts and practice prompt anatomy. |

---

### **Part G ‚Äì Instructor Extensions (Optional)**

- **Rubric Customization:** Add domain-specific criteria (e.g., for developers, writers, marketers).
- **Peer Review Option:** Learners swap prompts and score each other on clarity (5), creativity (5), and alignment (5).
- **Bloom‚Äôs Level Mapping:**
    - *Knowledge* ‚Äì MCQs (Recall)
    - *Application* ‚Äì Prompt construction
    - *Analysis* ‚Äì Iteration reflection
    - *Synthesis* ‚Äì Final refined prompt
    - *Evaluation* ‚Äì Instructor feedback

---

‚úÖ **Summary Insight:**

> This exam transforms learning into mastery. By designing, testing, and refining your own prompt, you bridge the gap between understanding AI and commanding it.
> 
> 
> Every iteration you document builds intuition ‚Äî the hallmark of a true Prompt Engineer.
>