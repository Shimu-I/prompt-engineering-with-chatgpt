# 3.7

## ðŸ§© **1.2.3.7 Metrics for Prompt Quality (Faithfulness, Helpfulness, Cost)**

---

### **Part A â€“ Concept Foundations**

### **1ï¸âƒ£ Why Prompt Quality Metrics Matter**

Until this point, youâ€™ve learned how to **write**, **debug**, and **iterate** prompts.

Now itâ€™s time to learn how to **measure** their performance â€” just like a software engineer measures code efficiency or accuracy.

> ðŸ§  Analogy:
> 
> 
> Imagine training an athlete without tracking speed, stamina, or accuracy â€” improvement becomes guesswork.
> 
> Similarly, prompt engineers who donâ€™t measure quality are just experimenting blindly.
> 
> Metrics turn intuition into mastery.
> 

---

### **2ï¸âƒ£ What Is a Prompt Quality Metric?**

A **Prompt Quality Metric** is a measurable criterion that evaluates how well a prompt produces desired results â€” balancing **accuracy**, **usefulness**, and **efficiency**.

The three gold standards are:

| **Metric** | **Definition** | **Goal** |
| --- | --- | --- |
| **Faithfulness** | How true the output is to the given input or source. | Prevent hallucination. |
| **Helpfulness** | How useful and relevant the output is for the userâ€™s goal. | Maximize utility. |
| **Cost** | How efficiently the output is generated (in tokens, time, and mental effort). | Optimize performance. |

âœ… Together, these form the **FHC Framework** â€” a benchmark for all professional prompt evaluations.

---

### **3ï¸âƒ£ Metric 1: Faithfulness**

**Definition:**

Faithfulness measures *truth alignment* â€” whether the AIâ€™s answer sticks to the facts, context, and instructions provided.

> ðŸ’¬ Example:
> 
> 
> **Input:** â€œSummarize the article on AI policy below.â€
> 
> **Bad Output:** Adds opinions not present in the text.
> 
> **Good Output:** Reflects only the articleâ€™s actual content.
> 

**Common Threats to Faithfulness:**

- Hallucination (invented facts)
- Incorrect reasoning
- Ignored context boundaries
- Data contamination from previous chats

**Fix Techniques:**

- Add explicit grounding (â€œOnly use the information in this passage.â€)
- Ask for evidence citations.
- Use step-by-step verification prompts (â€œExplain how you derived this answer.â€)

âœ… *Tip:* For critical workflows, always run a **â€œFact Check Passâ€** prompt before finalizing.

---

### **4ï¸âƒ£ Metric 2: Helpfulness**

**Definition:**

Helpfulness measures how well the AIâ€™s response serves the *intended human need* â€” clarity, completeness, and actionability.

| **Dimension** | **Question to Ask** |
| --- | --- |
| **Relevance** | Did it directly address the request? |
| **Depth** | Did it provide sufficient explanation or detail? |
| **Clarity** | Is it understandable by the intended audience? |
| **Tone Fit** | Does the voice match the role or purpose? |

> ðŸ§© Analogy: A faithful answer is â€œcorrect,â€ but a helpful answer is â€œuseful.â€
> 
> 
> Faithfulness makes AI *accurate*; helpfulness makes it *human-friendly.*
> 

**Improvement Strategies:**

- Add context on user background (â€œAssume the reader is a beginner.â€)
- Request actionable insights (â€œSummarize key takeaways in bullet points.â€)
- Encourage reflection (â€œWhat should the user do next?â€)

---

### **5ï¸âƒ£ Metric 3: Cost**

**Definition:**

Cost isnâ€™t only about API tokens or runtime â€” itâ€™s the **efficiency of your interaction.**

A well-engineered prompt minimizes *time, effort, and waste.*

| **Cost Dimension** | **Example** |
| --- | --- |
| **Token Cost** | â€œWrite concisely (under 200 words).â€ |
| **Cognitive Cost** | Easy-to-read instructions reduce user fatigue. |
| **Iteration Cost** | Well-designed prompts need fewer retries. |

âœ… *Goal:* Achieve â€œHigh Faithfulness + High Helpfulness + Low Cost.â€

---

### **6ï¸âƒ£ Balancing the Metrics (The FHC Triangle)**

Visualize the **Prompt Quality Triangle**:

```
        Faithfulness
            â–²
           / \
          /   \
 Helpfulnessâ€”â€”â€”Cost

```

- Increasing **helpfulness** often increases **cost** (more tokens, detail).
- Increasing **cost-efficiency** can risk **helpfulness** (too short, vague).
- Expert engineers find the **sweet spot** â€” *faithful, helpful, efficient.*

> âš™ï¸ Key Principle: â€œMeasure before you optimize.â€
> 

---

### **Part B â€“ Application and Examples**

### **Example 1 â€“ Measuring Faithfulness**

Prompt:

> â€œSummarize the following research abstract accurately. Do not add interpretations.â€
> 

âœ… *Evaluation:*

- Factual accuracy: 9/10
- Context adherence: 10/10
- Hallucinations: 0 detected
    
    â†’ Faithfulness Score: **9.5/10**
    

**Lesson:** Clear â€œno-interpretationâ€ instructions improve grounding.

---

### **Example 2 â€“ Measuring Helpfulness**

Prompt:

> â€œExplain quantum computing to a 10-year-old.â€
> 

**Version A Output:** Too complex.

**Version B Prompt (improved):** â€œExplain quantum computing to a 10-year-old using a candy analogy and simple language.â€

âœ… *Evaluation:*

- Relevance: 10/10
- Clarity: 9/10
- Engagement: 8/10
    
    â†’ Helpfulness Score: **9/10**
    

---

### **Example 3 â€“ Measuring Cost**

Prompt A:

> â€œExplain neural networks thoroughly, including math formulas and historical context.â€
> 
> 
> â†’ Tokens: 1,200 | Time: 18 sec
> 

Prompt B:

> â€œExplain neural networks simply, with one example and a 100-word limit.â€
> 
> 
> â†’ Tokens: 320 | Time: 5 sec
> 

âœ… *Trade-Off:*

A = Deep but costly

B = Efficient but less detailed

C (balanced) = Faithful (9), Helpful (8), Cost (7)

---

### **Example 4 â€“ Combined Metric Table**

| **Prompt Version** | **Faithfulness (10)** | **Helpfulness (10)** | **Cost (10)** | **Overall Quality (%)** |
| --- | --- | --- | --- | --- |
| V1 â€“ Vague | 6 | 5 | 9 | 67% |
| V2 â€“ Structured | 9 | 9 | 8 | 87% |
| V3 â€“ Detailed & Optimized | 10 | 9 | 7 | 88% |

> ðŸ“Š Conclusion: V3 gives near-optimal quality even with moderate cost â€” this is the engineerâ€™s balance zone.
> 

---

### **Example 5 â€“ Automating Evaluation**

Prompt:

```
Review this response using the FHC framework.
Rate faithfulness, helpfulness, and cost on a scale of 1â€“10.
Justify each score in one sentence.

```

âœ… *Use Case:* Self-assessment for model output â€” perfect for LMS or peer grading.

---

### **Part C â€“ Reflection, Quiz, and Mini Project**

### **Reflection Prompt**

> Which do you value more â€” faithfulness, helpfulness, or cost?
> 
> 
> How does that priority shift when working in research, education, or business contexts?
> 

---

### **Quick Quiz**

| **Q#** | **Question** | **Type** |
| --- | --- | --- |
| 1 | Define the 3 core prompt quality metrics. | Short Answer |
| 2 | What causes low faithfulness in outputs? | Short Answer |
| 3 | How can you improve helpfulness without increasing cost too much? | Short Answer |
| 4 | Why is cost more than just tokens? | Short Answer |
| 5 | What is the FHC sweet spot? | Short Answer |

---

### **Answer Key**

| **Q#** | **Answer** | **Explanation** |
| --- | --- | --- |
| 1 | Faithfulness, Helpfulness, Cost. | Core quality trio. |
| 2 | Hallucinations, vague context, or poor grounding. | Lack of control. |
| 3 | Add context and structure, not length. | Efficiency through clarity. |
| 4 | Includes time, mental effort, and iteration count. | Broader efficiency view. |
| 5 | Balanced trade-off among all three metrics. | Optimal prompt quality. |

---

### **Mini Project: â€œFHC Prompt Benchmarkâ€**

> Goal: Build and test a quantitative quality scoring framework for your own prompts.
> 

| **Step** | **Instruction** | **Example** |
| --- | --- | --- |
| 1ï¸âƒ£ | Pick a task (e.g., â€œGenerate a product description.â€) |  |
| 2ï¸âƒ£ | Create 3 different prompt versions. | Vague / Structured / Optimized |
| 3ï¸âƒ£ | Run each and score using FHC metrics. | Faithful (8â€“10), Helpful (7â€“9), Cost (5â€“10) |
| 4ï¸âƒ£ | Record results in a table. | Compare percentages |
| 5ï¸âƒ£ | Reflect on which prompt hit the sweet spot. | Write a short evaluation (100 words). |

âœ… *Extension:* Automate scoring by instructing AI to apply the FHC framework â€” a precursor to **Prompt Evaluation APIs** used in advanced AI pipelines.

---

### **Instructor Notes (Optional)**

| **Criterion** | **Score (1â€“10)** | **Focus Area** |
| --- | --- | --- |
| Metric Understanding |  | Can define and apply FHC correctly |
| Analytical Rigor |  | Uses quantitative reasoning |
| Optimization Skill |  | Balances accuracy and cost |
| Reflection Insight |  | Demonstrates contextual awareness |

---

âœ… **Summary Insight:**

> A true Prompt Engineer doesnâ€™t rely on intuition â€” they rely on metrics.
> 
> 
> The **FHC Framework** (Faithfulnessâ€“Helpfulnessâ€“Cost) transforms prompting from an art into a measurable science.
> 
> When you can score and balance your prompts like code performance, youâ€™ve crossed the line from *user* to *engineer.*
> 

---