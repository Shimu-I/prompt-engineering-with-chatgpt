# 3.4

## 🧩 **1.2.3.4 Common Pitfalls and How to Fix Them**

---

### **Part A – Concept Foundations**

### **1️⃣ Why Prompt Pitfalls Matter**

Even skilled AI users fall into predictable traps that lead to **hallucinated**, **incomplete**, or **irrelevant** outputs.

The difference between a beginner and a prompt engineer isn’t avoiding mistakes — it’s **recognizing, naming, and fixing** them fast.

> 🧠 Analogy:
> 
> 
> Prompting is like steering a plane through turbulence — you can’t stop the wind (AI uncertainty), but you can adjust your controls.
> 

---

### **2️⃣ The Anatomy of a Prompt Failure**

AI errors usually come from one (or more) of these three causes:

| **Error Type** | **Root Cause** | **Example Output** |
| --- | --- | --- |
| **Ambiguity** | Vague or missing context | “Here’s a generic answer…” |
| **Overload** | Too many goals or mixed tasks | “Here’s something partially correct but scattered.” |
| **Contradiction** | Conflicting tone or instructions | “I’m formal and casual at the same time.” |

Each one reduces coherence, clarity, and accuracy.

---

### **3️⃣ Top 7 Prompt Engineering Pitfalls**

| **Pitfall** | **Description** | **Fix Strategy** |
| --- | --- | --- |
| **1. Vague Prompts** | No clear goal or format. | Add role, audience, and structure. |
| **2. Overstuffed Prompts** | Multiple tasks at once. | Split into smaller sub-prompts. |
| **3. Hidden Assumptions** | Expecting the AI to “read your mind.” | Explicitly define background info. |
| **4. Unbounded Outputs** | AI rambles indefinitely. | Add output length and structure limits. |
| **5. Ambiguous Tone** | No persona or audience clarity. | Use “Act as…” or tone parameters. |
| **6. Schema Drift** | JSON, table, or structure inconsistencies. | Enforce strict format with examples. |
| **7. Missing Constraints** | AI fills gaps creatively — not accurately. | Add rules, context, and purpose clauses. |

> 💬 Core Lesson: Every unclear input becomes an unpredictable output.
> 

---

### **4️⃣ The "Prompt Debugging Mindset"**

When the AI fails, don’t blame it — **debug it** like software.

Ask these five diagnostic questions:

1️⃣ Did I define **one clear goal**?

2️⃣ Did I specify **who or what the model is acting as**?

3️⃣ Did I include **context or examples**?

4️⃣ Did I describe **output structure or limits**?

5️⃣ Did I review the **previous message history** for contamination?

✅ If you fix even one missing element, quality can improve by 50% or more.

---

### **Part B – Application and Examples**

### **Example 1 – Vague Prompt**

**Prompt:**

> “Write something about leadership.”
> 

**Output:**

> “Leadership is important in every organization…”
> 

**Problem:** Generic, directionless.

**Fix:**

> “Act as a leadership coach. Write a 150-word motivational message for new managers on empathetic leadership, using one real-life example.”
> 

✅ *Improved output:* Contextual, structured, and inspiring.

---

### **Example 2 – Overstuffed Prompt**

**Prompt:**

> “Explain AI, list its pros and cons, write a 200-word essay, and include a poem.”
> 

**Problem:** Overloaded tasks → Confused structure.

**Fix (Decompose):**

1️⃣ “Explain AI in one paragraph.”

2️⃣ “List 3 pros and cons.”

3️⃣ “Write a short AI-themed poem.”

✅ Clear sub-prompts create consistent quality across all tasks.

---

### **Example 3 – Contradictory Tone**

**Prompt:**

> “Write a short, funny but formal paragraph on data privacy.”
> 

**Problem:** “Funny” vs “formal” → Style clash.

**Fix:**

> Choose one primary tone: “Write a witty but professional paragraph using business humor about data privacy.”
> 

✅ Result: Aligned personality → Natural tone.

---

### **Example 4 – Schema Drift (Technical Prompt Error)**

**Prompt:**

> “Output a JSON with name, age, and skills.”
> 
> 
> *(AI returns inconsistent structure)*
> 

**Fix:**

> “Return JSON only in this format:
> 
> 
> ```json
> { "name": "string", "age": "integer", "skills": ["string"] }
> 
> ```
> 
> Do not include extra text outside the JSON.”
> 

✅ Output now validates perfectly — no schema drift.

---

### **Example 5 – Hidden Assumption**

**Prompt:**

> “Summarize the latest AI policies.”
> 

**Problem:** The model doesn’t have live data (unless browsing enabled).

**Fix:**

> “Using your training knowledge (up to April 2024), summarize general trends in AI policy — not live events. Add a note that this information may be outdated.”
> 

✅ Clarity prevents hallucination.

---

### **Example 6 – Missing Constraints**

**Prompt:**

> “Explain climate change.”
> 

**Fix:**

> “Act as a high school science teacher. Explain climate change in 3 short paragraphs (definition, causes, solutions). Use simple language.”
> 

✅ Constraints direct clarity and audience fit.

---

### **Example 7 – History Contamination**

**Scenario:** The chat history shifts model behavior.

> 💡 Solution: Use fresh sessions for major context changes, or include system reminders like:
> 
> 
> “Forget previous context. Start a new analysis based only on this prompt.”
> 

✅ This prevents “context bleed” from older messages.

---

### **Part C – Reflection, Quiz, and Mini Project**

### **Reflection Prompt**

> Think back to a time when AI gave you an irrelevant or confusing answer.
> 
> 
> Was the issue the model — or your prompt?
> 
> Which of the 7 pitfalls do you suspect caused it?
> 

---

### **Quick Quiz**

| **Q#** | **Question** | **Type** |
| --- | --- | --- |
| 1 | Define “prompt ambiguity.” | Short Answer |
| 2 | What’s one symptom of an overloaded prompt? | Short Answer |
| 3 | What is schema drift, and how do you prevent it? | Short Answer |
| 4 | Why should tone be defined clearly? | Short Answer |
| 5 | What’s the difference between a failed prompt and a failed model? | Short Answer |

---

### **Answer Key**

| **Q#** | **Correct Answer** | **Explanation** |
| --- | --- | --- |
| 1 | Unclear or underspecified instruction. | Causes varied or irrelevant outputs. |
| 2 | Model gives inconsistent or mixed responses. | Task overload. |
| 3 | Output deviates from requested JSON/table schema; fix with explicit format examples. | Structure enforcement. |
| 4 | Prevents contradictions and ensures target audience alignment. | Tone consistency. |
| 5 | Failed prompt = unclear design; failed model = systemic error. | User vs model issue. |

---

### **Mini Project: “Prompt Debugging Workshop”**

> Goal: Identify, diagnose, and fix 3 bad prompts.
> 

| **Step** | **Instruction** | **Example** |
| --- | --- | --- |
| 1 | Write or find 3 prompts that produce poor results. | e.g., “Explain technology in general.” |
| 2 | Diagnose each using the 7 Pitfall Table. | Vague / Missing context. |
| 3 | Redesign each prompt to fix the issue. | Add structure, tone, or clarity. |
| 4 | Compare outputs (before vs after). | Evaluate for clarity, accuracy, tone. |
| 5 | Write a 150-word reflection summarizing what changed and why. | “Adding constraints improved precision.” |

✅ *Extension:* Use AI to self-critique your “before” and “after” versions for clarity and compliance.

---

### **Instructor Notes (Optional)**

| **Criterion** | **Score (1–10)** | **Focus Area** |
| --- | --- | --- |
| Diagnostic skill |  | Can identify common prompt errors |
| Correction accuracy |  | Rewrites prompt effectively |
| Reflection insight |  | Awareness of personal prompting weaknesses |
| Quality comparison |  | Evidence of improved results |

---

✅ **Summary Insight:**

> Every prompt failure is a diagnostic gift.
> 
> 
> Learning to debug your instructions turns frustration into intuition.
> 
> Master prompt engineers don’t chase perfection — they build *repair skills* that let them adapt to any model, any task, and any constraint.
>