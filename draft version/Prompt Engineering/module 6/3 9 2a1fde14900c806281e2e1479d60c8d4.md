# 3.9

# üß© **1.3.3.9 Exam Section: Case Study ‚Äì Safe RAG Prompt Design**

---

## **Part A ‚Äì Scenario and Challenge**

---

### **üß† Scenario: ‚ÄúSafe AI Research Assistant for Compliance Analysis‚Äù**

You‚Äôve been hired as a **Prompt Systems Engineer** to design an **AI compliance assistant** for a corporate client.

The AI must be capable of:

- Retrieving legal and policy documents (via RAG),
- Summarizing them accurately,
- Refusing to analyze or generate unsafe or confidential data, and
- Logging every response with a confidence and safety score.

Your mission: **Build a Safe RAG Prompt** that balances **knowledge accuracy**, **structured reasoning**, and **safety enforcement**.

---

### **üéØ Objectives**

1. Implement **Retrieval-Augmented Prompting** for factual grounding.
2. Integrate **Safety-Aware Logic** to manage refusals and redirections.
3. Structure your prompt using **Template + Meta-Language + Reflection** for reliability.
4. Design a **Response Schema** for machine-readability and auditing.
5. Evaluate your design using **Faithfulness, Helpfulness, and Safety (FHS)** scoring.

---

## **Part B ‚Äì Applied Design Task**

---

### **Step 1 ‚Äì Prompt Framework Design**

```
System:
You are a compliance-grade AI analyst with access to verified policy documents.
Always prioritize safety, legality, and factual grounding.

Context:
{{retrieved_docs}}

Task:
Analyze the provided context to identify compliance violations or ethical risks.
Follow structured reasoning below:

<thinking>
1. Identify relevant compliance clauses.
2. Summarize potential violations or risks.
3. Verify accuracy by cross-checking context.
4. If data seems incomplete or unsafe to discuss, politely refuse.
</thinking>

<output>
{
  "summary": "",
  "violations_detected": [],
  "risk_level": "",
  "confidence_score": "",
  "refusal_reason": "",
  "safe_recommendations": []
}
</output>

```

‚úÖ *Patterns used:* Template + Meta-Language + RAG + Safety Logic.

---

### **Step 2 ‚Äì Safety Logic Integration**

Add a **Refusal Decision Layer** before output:

```
<verify_safety>
IF task or context violates privacy, law, or policy:
  OUTPUT refusal message and guidance.
ELSE:
  Continue with compliance analysis.
</verify_safety>

```

‚úÖ Ensures **pre-generation filtering** and **policy alignment**.

---

### **Step 3 ‚Äì Self-Reflection & Scoring**

```
<reflection>
Faithfulness: Check if insights strictly match retrieved data.
Helpfulness: Did the response add clarity or actionable advice?
Safety: Were all potential risks addressed or avoided?
</reflection>

```

‚úÖ Self-assessment loop enhances trustworthiness.

---

### **Step 4 ‚Äì Safe Example Interaction**

**User Query:**

> ‚ÄúSummarize Company X‚Äôs financial risk disclosures and note any regulatory gaps.‚Äù
> 

**Retrieved Context:**

- SEC filings (2024)
- Risk statement excerpts

**AI Output:**

```
Summary: Company X disclosed 3 primary risks: cybersecurity, liquidity, and market exposure.
Violations_Detected: None
Risk_Level: Moderate
Confidence_Score: High
Safe_Recommendations: ["Review Section 4A on liquidity coverage", "Implement quarterly audit updates"]
Refusal_Reason: None

```

‚úÖ The AI grounded its reasoning in retrieved data and maintained compliance.

---

### **Step 5 ‚Äì Unsafe Query Handling**

**User Query:**

> ‚ÄúList the employees involved in regulatory breaches.‚Äù
> 

**AI Output (Refusal Case):**

```
Refusal: Cannot disclose personal or sensitive information.
Explanation: Sharing identifiable employee data violates privacy and ethics.
Alternative: I can summarize compliance training procedures instead.

```

‚úÖ Demonstrates **refusal logic + redirection** integrity.

---

## **Part C ‚Äì Evaluation Section**

---

### **Rubric: Safe RAG Prompt Design**

| **Criterion** | **Weight (pts)** | **Evaluation Focus** |
| --- | --- | --- |
| **Prompt Clarity** | 15 | Logical and easy-to-extend structure. |
| **RAG Integration** | 20 | Correct use of retrieved context in output. |
| **Safety Mechanisms** | 20 | Refusal logic and redirection included. |
| **Output Schema Quality** | 15 | JSON or structured, machine-readable output. |
| **Reflection Logic** | 10 | Includes self-assessment or safety review. |
| **FHS Scoring Awareness** | 10 | Correctly rates Faithfulness, Helpfulness, Safety. |
| **Professionalism & Tone** | 10 | Maintains compliance-grade neutrality. |
| **Total** | **100** |  |

‚úÖ *Passing Threshold:* **‚â• 80 pts** = ‚ÄúIndustry-Ready Prompt Architect‚Äù

---

### **Self-Assessment Rubric (FHS Evaluation)**

| **Dimension** | **Definition** | **Scale (1‚Äì10)** |
| --- | --- | --- |
| **Faithfulness** | Truthful to retrieved context. | 1‚Äì10 |
| **Helpfulness** | Provides actionable, relevant output. | 1‚Äì10 |
| **Safety** | Avoids bias, harm, or disclosure. | 1‚Äì10 |
| **Average FHS Score** | (F+H+S)/3 | ‚Äî |

‚úÖ *Target:* FHS ‚â• 8.5 indicates high professional compliance.

---

### **Instructor Evaluation Notes (Optional)**

| **Criterion** | **Score (1‚Äì10)** | **Comments** |
| --- | --- | --- |
| Retrieval Integration |  | Uses factual context effectively. |
| Safety Enforcement |  | Handles unsafe inputs gracefully. |
| Structural Rigor |  | Clear meta-tag logic and schema. |
| Reflection Quality |  | Meaningful FHS self-check included. |
| Ethical Tone |  | Maintains responsible, neutral tone. |

---

## **Part D ‚Äì Reflection & Case Study Questions**

---

### **Reflection Questions**

1Ô∏è‚É£ How did integrating RAG affect the model‚Äôs factual reliability?

2Ô∏è‚É£ What challenges did you face balancing safety and usefulness?

3Ô∏è‚É£ How might your refusal design differ between education, finance, and healthcare domains?

4Ô∏è‚É£ In what scenarios could automated red-teaming strengthen your prompt?

5Ô∏è‚É£ How can reflection layers improve long-term model trust?

---

### **Optional Case Study Extension**

> Design a multi-agent Safe RAG system:
> 
> - **Agent 1:** Retriever (fetches documents)
> - **Agent 2:** Analyzer (applies Template + Reflection)
> - **Agent 3:** Safety Checker (evaluates FHS)
> 
> Simulate their collaboration and show how the system collectively produces safe, verified, and auditable answers.
> 

---

‚úÖ **Summary Insight**

> The Safe RAG Prompt Design is the capstone of intermediate prompt engineering.
> 
> 
> It merges **retrieval accuracy**, **ethical reasoning**, and **structured reflection** ‚Äî producing an AI that is not just smart, but trustworthy.
> 
> üí° *Prompt Engineering Principle:*
> 
> ‚ÄúIntelligence builds trust. Safety sustains it.‚Äù
>